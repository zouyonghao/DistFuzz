; generated by vstart.sh on Wed 14 Apr 2021 08:57:48 AM UTC
[client.vstart.sh]
        num mon = 1
        num osd = 3
        num mds = 1
        num mgr = 1
        num rgw = 0
        num ganesha = 0

[global]
        fsid = faef5cf5-afb1-4dbc-a26f-5f94556f2db1
        osd failsafe full ratio = .99
        mon osd full ratio = .99
        mon osd nearfull ratio = .99
        mon osd backfillfull ratio = .99
        mon_max_pg_per_osd = 1000
        erasure code dir = /home/zyh/ceph/build//lib
        plugin dir = /home/zyh/ceph/build//lib
        filestore fd cache size = 32
        run dir = /home/zyh/distributed-system-test/ceph_test/bin/out
        crash dir = /home/zyh/distributed-system-test/ceph_test/bin/out
        enable experimental unrecoverable data corrupting features = *
        osd_crush_chooseleaf_type = 0
        debug asok assert abort = true
        ms bind msgr2 = true
        ms bind msgr1 = true
        
        lockdep = true
        auth cluster required = none
        auth service required = none
        auth client required = none
[client]
        keyring = /home/zyh/distributed-system-test/ceph_test/bin/keyring
        log file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.$pid.log
        admin socket = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.$pid.asok

        ; needed for s3tests
        rgw crypt s3 kms backend = testing
        rgw crypt s3 kms encryption keys = testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo= testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
        rgw crypt require ssl = false
        ; uncomment the following to set LC days as the value in seconds;
        ; needed for passing lc time based s3-tests (can be verbose)
        ; rgw lc debug interval = 10
        
[mds]

        log file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.log
        admin socket = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.asok
        chdir = ""
        pid file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.pid
        heartbeat file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.heartbeat

        mds data = /home/zyh/distributed-system-test/ceph_test/bin/dev/mds.$id
        mds root ino uid = 1001
        mds root ino gid = 1001
        
[mgr]
        mgr data = /home/zyh/distributed-system-test/ceph_test/bin/dev/mgr.$id
        mgr module path = /home/zyh/ceph//src/pybind/mgr
        cephadm path = /home/zyh/ceph//src/cephadm/cephadm

        log file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.log
        admin socket = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.asok
        chdir = ""
        pid file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.pid
        heartbeat file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.heartbeat

        
[osd]

        log file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.log
        admin socket = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.asok
        chdir = ""
        pid file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.pid
        heartbeat file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.heartbeat

        osd_check_max_object_name_len_on_startup = false
        osd data = /home/zyh/distributed-system-test/ceph_test/bin/dev/osd$id
        osd journal = /home/zyh/distributed-system-test/ceph_test/bin/dev/osd$id/journal
        osd journal size = 100
        osd class tmp = out
        osd class dir = /home/zyh/ceph/build//lib
        osd class load list = *
        osd class default list = *
        osd fast shutdown = false

        filestore wbthrottle xfs ios start flusher = 10
        filestore wbthrottle xfs ios hard limit = 20
        filestore wbthrottle xfs inodes hard limit = 30
        filestore wbthrottle btrfs ios start flusher = 10
        filestore wbthrottle btrfs ios hard limit = 20
        filestore wbthrottle btrfs inodes hard limit = 30
        bluestore fsck on mount = true
        bluestore block create = true
        bluestore block db path = /home/zyh/distributed-system-test/ceph_test/bin/dev/osd$id/block.db.file
        bluestore block db size = 1073741824
        bluestore block db create = true
        bluestore block wal path = /home/zyh/distributed-system-test/ceph_test/bin/dev/osd$id/block.wal.file
        bluestore block wal size = 1048576000
        bluestore block wal create = true

        ; kstore
        kstore fsck on mount = true
        osd objectstore = bluestore

        debug ms = 5
        
[mon]
        mgr initial modules = dashboard restful iostat

        log file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.log
        admin socket = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.asok
        chdir = ""
        pid file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.pid
        heartbeat file = /home/zyh/distributed-system-test/ceph_test/bin/out/$name.heartbeat

        debug ms = 5
        debug mon = 5
        
        mon cluster log file = /home/zyh/distributed-system-test/ceph_test/bin/out/cluster.mon.$id.log
        osd pool default erasure code profile = plugin=jerasure technique=reed_sol_van k=2 m=1 crush-failure-domain=osd
[mon.a]
        host = 192.168.169.123
        mon data = /home/zyh/distributed-system-test/ceph_test/bin/dev/mon.a
[global]
        mon host =  [v2:192.168.169.123:40743,v1:192.168.169.123:40744]
[mgr.x]
        host = 192.168.169.123
[osd.0]
        host = 192.168.169.123
        ms_bind_port_min = 6800
        ms_bind_port_max = 6807
[osd.1]
        host = 192.168.169.123
        ms_bind_port_min = 6810
        ms_bind_port_max = 6817
[osd.2]
        host = 192.168.169.123
        ms_bind_port_min = 6820
        ms_bind_port_max = 6827
[mds.a]
        host = 192.168.169.123
